# -*- coding: utf-8 -*-
"""PE_Rag.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Ud377aYSS9vxvko7uJ0u2t6yISYyj_7c
"""

!pip -q install transformers sentence-transformers faiss-cpu

from sentence_transformers import SentenceTransformer
import faiss
import numpy as np
from transformers import pipeline

docs = [
    ("doc1", "Private equity funds are closed-end investment vehicles focusing on long-term ownership."),
    ("doc2", "Carried interest is the GP profit share, usually 20% above an 8% IRR hurdle."),
    ("doc3", "LBO means Leveraged Buyout â€” buying companies using high debt against assets."),
    ("doc4", "PE exits include IPOs, strategic sales, and secondary buyouts."),
    ("doc5", "IRR evaluates fund performance across the investment lifecycle."),
]

embedder = SentenceTransformer("all-MiniLM-L6-v2")



vectors = embedder.encode(new_list)
vectors = np.array(vectors, dtype="float32")
dim = vectors.shape[1]
print(dim)

index = faiss.IndexFlatL2(dim)
index.add(vectors)

llm = pipeline("text-generation",model="distilgpt2")

def format_context(chunks, style="bullet"):
    if style == "bullet":
        return "\n".join([f"- {text} (source: {src})" for text, src in chunks])
    if style == "para":
        return " ".join([f"{text} (source: {src})" for text, src in chunks])
    if style == "qa":
        formatted = ""
        for text, src in chunks:
            formatted += f"Fact: {text}\nSource: {src}\n\n"
        return formatted.strip()
    return format_context(chunks, "bullet")

def retrieve(query, k=3, threshold=1.5):
    q_vec = embedder.encode([query])
    q_vec = np.array(q_vec, dtype="float32")
    distances, indices = index.search(q_vec, k)
    retrieve = []
    for i in indices[0]:
        retrieve.append((docs[i][1], docs[i][0]))
    if not retrieve:
        return [], None, None
    best_dis = distances[0][0]
    if best_dis > threshold:
        return [], None, None
    return retrieve, best_dis, indices[0]

PROMPT_TEMPLATES = {
    "detailed": """You are a Private Equity expert.
Answer the question using the context.

Context:
{context}

Question: {query}
Answer:""",

    "concise": """Use context to answer briefly.

Context:
{context}

Question: {query}
Answer:""",

    "analyst": """You are a senior PE analyst.
Write a professional analysis.

Context:
{context}

Query: {query}
Analysis:"""
}

def gen_ans(query, retrieved, template_style="detailed"):
    if not retrieved:
        return "No proper context", []

    context_pairs = []
    for text, src in retrieved:
        context_pairs.append((text, src))

    context = format_context(context_pairs, template_style)

    prompt = PROMPT_TEMPLATES[template_style].format(
        context=context,
        query=query
    )

    result = llm(prompt, max_new_tokens=150, num_return_sequences=1)
    generated_text = result[0]["generated_text"]

    sources = []
    for text, src in retrieved:
        sources.append({"doc_id": src, "text": text[:60] + "..."})

    return generated_text.strip(), sources

def rag(query, k=3):
    retrieved, best_score, retrieved_indices = retrieve(query, k)
    final_answer, citations = gen_ans(query, retrieved)
    return retrieved, final_answer, citations, best_score

questions = [
    "What is carried interest in PE funds?",
    "Explain leveraged buyouts in private equity",
    "What exit routes do PE firms take?",
    "How is IRR used in private equity?"
]

for q in questions:
    for k in [3, 5, 10]:
        retrieved, answer, citations, score = rag(q, k)
        print("\n" + "="*50)
        print(f"Query: {q} | K={k}")
        print(f"Similarity score: {score}")
        print("\nRetrieved Context:")
        for text, src in retrieved:
            print(f"[{src}] {text}")
        print("\nGenerated Answer:")
        print(answer)
        print("\nCitations used:")
        print(citations)

