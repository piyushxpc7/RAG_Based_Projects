# -*- coding: utf-8 -*-
"""chunking_strategy

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XaM42veonp914Tn1AIo71wJyAD6a5kjV
"""

!pip install -q sentence-transformers transformers torch faiss-cpu nltk PyPDF2 requests accelerate

import os
import re
import requests
import nltk
import torch
import PyPDF2
import numpy as np
import json
import nltk

# Download both old and new punkt versions - covers all cases
nltk.download('punkt')       # classic punkt
nltk.download('punkt_tab')   # new tab-separated punkt (required in NLTK ≥ 3.8)

from sentence_transformers import SentenceTransformer
from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline
import faiss

from typing import List, Dict, Tuple
from collections import defaultdict

nltk.download('punkt', quiet=True)

embedder = SentenceTransformer('all-MiniLM-L6-v2')
model_name = "microsoft/Phi-3.5-mini-instruct"
tokenizer = AutoTokenizer.from_pretrained(model_name,trust_remote_code = True)
model = AutoModelForCausalLM.from_pretrained(
    model_name,
    torch_dtype = torch.float16,
    device_map = "auto",
    trust_remote_code = True
)

generator = pipeline(
    "text-generation",
    model = model,
    tokenizer = tokenizer,
    max_new_tokens = 512,
    temperature = 0.3,
    do_sample = True
)

document_urls = [
    "https://arxiv.org/pdf/2509.11420.pdf",     # Trading-R1
    "https://arxiv.org/pdf/2107.09051.pdf",     # AI in Finance
    "https://arxiv.org/pdf/2303.17564.pdf",     # BloombergGPT
    "https://arxiv.org/pdf/2508.14301.pdf",     # Finance Journals
    "https://arxiv.org/pdf/1003.4881.pdf",      # DCF Valuation
    "https://arxiv.org/pdf/2507.09020.pdf",     # ESG
    "https://arxiv.org/pdf/2503.18675.pdf",     # Fintech
    "https://arxiv.org/pdf/2112.14902.pdf",     # Academic Finance
    "https://arxiv.org/pdf/2311.10723.pdf",     # LLMs in Finance
    "https://www.intc.com/filings-reports/all-sec-filings/content/0000050863-25-000009/0000050863-25-000009.pdf"  # Intel 10-K
]

def extract_text_from_pdf(url: str, local_path: str) -> str:
    if not os.path.exists(local_path):
        print(f"Downloading {local_path}...")
        response = requests.get(url, timeout=30)
        response.raise_for_status()
        with open(local_path, "wb") as f:
            f.write(response.content)

    text = ""
    with open(local_path, "rb") as f:
        reader = PyPDF2.PdfReader(f)
        for page in reader.pages[:50]:
            try:
                page_text = page.extract_text()
                if page_text:
                    text += page_text + "\n"
            except Exception:
                continue

    return text

import requests
import time

def download_pdf_robust(url, local_path, max_retries=3):
    """More reliable PDF downloader with retries and progress check"""
    for attempt in range(max_retries):
        try:
            print(f"Downloading {local_path} (attempt {attempt+1}/{max_retries})...")
            response = requests.get(url, timeout=60, stream=True)
            response.raise_for_status()

            total_size = int(response.headers.get('content-length', 0))
            downloaded = 0

            with open(local_path, 'wb') as f:
                for chunk in response.iter_content(chunk_size=8192):
                    if chunk:
                        f.write(chunk)
                        downloaded += len(chunk)
                        # Optional: show progress
                        if total_size > 0:
                            print(f"\rProgress: {downloaded/total_size*100:.1f}%", end="")

            print()  # new line after progress

            # Basic integrity check
            if os.path.getsize(local_path) < 10000:  # less than 10KB → probably failed
                raise ValueError("Downloaded file too small - likely incomplete")

            return True

        except Exception as e:
            print(f"Attempt {attempt+1} failed: {e}")
            time.sleep(5)  # wait before retry

    print(f"Failed to download {url} after {max_retries} attempts")
    return False

def extract_text_from_pdf(url: str, local_path: str) -> str:
    try:
        # Download only if missing or corrupted
        if not os.path.exists(local_path) or os.path.getsize(local_path) < 20000:
            success = download_pdf_robust(url, local_path)
            if not success:
                return ""

        with open(local_path, 'rb') as f:
            reader = PyPDF2.PdfReader(f)
            text = ""
            for page in reader.pages[:50]:  # keep your limit
                try:
                    page_text = page.extract_text()
                    if page_text:
                        text += page_text + "\n"
                except:
                    continue
        return text

    except Exception as e:
        print(f"Error processing {local_path}: {e}")
        return ""

def recursive_chunking(text: str, chunk_size: int = 1000, chunk_overlap: int = 200) -> List[str]:
    separators = ["\n\n", "\n", ". ", " ", ""]

    def split_text(txt, seps):
        if not seps or len(txt) <= chunk_size:
            return [txt] if txt else []

        sep = seps[0]
        splits = txt.split(sep)
        chunks = []
        current = ""

        for part in splits:
            if len(current) + len(part) + len(sep) <= chunk_size:
                current += part + sep
            else:
                if current:
                    chunks.append(current.strip())
                if len(part) > chunk_size:
                    chunks.extend(split_text(part, seps[1:]))
                    current = ""
                else:
                    if chunks and chunk_overlap > 0:
                        overlap = chunks[-1][-chunk_overlap:]
                        current = overlap + part + sep
                    else:
                        current = part + sep

        if current:
            chunks.append(current.strip())
        return chunks

    return split_text(text, separators)

def semantic_chunking(text: str, max_chunk_size: int = 2000) -> List[str]:
    sentences = nltk.sent_tokenize(text)
    sections = []
    current = ""

    for sent in sentences:
        if len(current) + len(sent) < max_chunk_size:
            current += sent + " "
        else:
            if current:
                sections.append(current.strip())
            current = sent + " "

    if current:
        sections.append(current.strip())

    chunks = []
    for section in sections[:10]:  # Limit to prevent excessive calls
        prompt = f"""<|user|>
Analyze this text and split it into 2-4 coherent sections based on topic shifts.
Output ONLY the sections separated by '---'. No explanations.
Text: {section[:1500]}
<|assistant|>"""

        try:
            result = generator(prompt, max_new_tokens=800, temperature=0.1)
            response = result[0]['generated_text'].split('<|assistant|>')[-1].strip()
            topic_chunks = [c.strip() for c in response.split('---') if c.strip()]
            chunks.extend(topic_chunks if topic_chunks else [section])
        except:
            chunks.append(section)

    return chunks

def sentence_window_chunking(text: str, window_size: int = 2) -> List[Dict]:
    """Sentence-level chunks with surrounding context window metadata"""
    sentences = nltk.sent_tokenize(text)
    chunks = []

    for i, sentence in enumerate(sentences):
        chunk = {
            'main_sentence': sentence,
            'index': i,
            'window_start': max(0, i - window_size),
            'window_end': min(len(sentences), i + window_size + 1),
            'sentences': sentences  # reference to full list
        }
        chunks.append(chunk)

    return chunks

def expand_sentence_context(chunk: Dict) -> str:
    sents = chunk['sentences']
    return " ".join(sents[chunk['window_start']:chunk['window_end']])

class SimpleVectorStore:
    def __init__(self, embedder):
        self.embedder = embedder
        self.chunks = []
        self.embeddings = None
        self.index = None

    def add_chunks(self, chunks: List):
        self.chunks = chunks
        texts = []
        for c in chunks:
            if isinstance(c, dict):
                texts.append(c.get('main_sentence') or c.get('text') or str(c))
            else:
                texts.append(str(c))

        print("Generating embeddings...", end=" ")
        self.embeddings = self.embedder.encode(texts, show_progress_bar=True)
        dim = self.embeddings.shape[1]

        self.index = faiss.IndexFlatL2(dim)
        self.index.add(self.embeddings.astype('float32'))
        print("done")

    def retrieve(self, query: str, k: int = 3) -> List[Tuple[Dict, float]]:
        q_emb = self.embedder.encode([query])
        distances, indices = self.index.search(q_emb.astype('float32'), k)
        return [(self.chunks[i], float(d)) for i, d in zip(indices[0], distances[0])]

def generate_answer(question: str, context_chunks: List[str]) -> str:
    context = "\n\n".join(context_chunks[:3])
    prompt = f"""<|user|>
Answer the question based on the context provided. Be concise and accurate.
Context:
{context[:2000]}
Question: {question}
<|assistant|>"""

    try:
        result = generator(prompt, max_new_tokens=200, temperature=0.3)
        answer = result[0]['generated_text'].split('<|assistant|>')[-1].strip()
        return answer
    except Exception as e:
        return f"[Generation Error] {e}"

def evaluate_strategy(strategy_name: str, chunking_func, questions: List[Dict]):
    print(f"\n{'═'*80}")
    print(f"  EVALUATING STRATEGY: {strategy_name.upper()}")
    print(f"{'═'*80}\n")

    all_chunks = []
    for doc in documents:
        if strategy_name.lower() == "sentence_window":
            chunks = chunking_func(doc['text'])
            for chunk in chunks:
                chunk['doc_id'] = doc['id']
                chunk['text'] = chunk['main_sentence']  # for embedding
                all_chunks.append(chunk)
        else:
            chunk_texts = chunking_func(doc['text'])
            for txt in chunk_texts:
                all_chunks.append({
                    'text': txt,
                    'doc_id': doc['id'],
                    'source': doc['source']
                })

    print(f"→ Created {len(all_chunks):,} chunks")

    # Build vector index once
    vectorstore = SimpleVectorStore(embedder)
    vectorstore.add_chunks(all_chunks)

    results = []
    for i, item in enumerate(questions, 1):
        q = item['q']
        retrieved = vectorstore.retrieve(q, k=5)

        if strategy_name.lower() == "sentence_window":
            context_texts = [expand_sentence_context(c) for c, _ in retrieved]
        else:
            context_texts = [c['text'] for c, _ in retrieved]

        answer = generate_answer(q, context_texts)

        result_entry = {
            'question': q,
            'answer': answer,
            'retrieved_chunks': context_texts[:3],
            'distances': [d for _, d in retrieved[:3]]
        }
        results.append(result_entry)

        print(f"\nQ{i:2d}: {q}")
        print(f"Answer (first 200 chars): {answer[:200]}{'...' if len(answer)>200 else ''}")
        print(f"Top distances: {[f'{d:.3f}' for d in result_entry['distances']]}")

    return results

test_questions = [
    # Document 1 – Trading / RL paper
    {"q": "What is Trading-R1 and how does it work?", "doc": 1},
    {"q": "How does reinforcement learning improve trading decisions?", "doc": 1},
    {"q": "What problem does Trading-R1 aim to solve in financial markets?", "doc": 1},
    {"q": "What role does reward design play in Trading-R1?", "doc": 1},

    # Document 2 – ML / RL fundamentals
    {"q": "What is the difference between supervised learning and reinforcement learning?", "doc": 2},
    {"q": "How does an agent learn from rewards and penalties?", "doc": 2},
    {"q": "What is the exploration–exploitation tradeoff?", "doc": 2},
    {"q": "Why is reward shaping important in reinforcement learning?", "doc": 2},

    # Document 3 – Trading strategies / signals
    {"q": "What market signals are commonly used in algorithmic trading?", "doc": 3},
    {"q": "How does volatility affect trading strategies?", "doc": 3},
    {"q": "What are the risks of overfitting in trading models?", "doc": 3},

    # Document 4 – Risk & evaluation
    {"q": "How are trading strategies evaluated for performance?", "doc": 4},
    {"q": "What metrics are used to measure risk in trading systems?", "doc": 4},
    {"q": "Why is drawdown an important metric in finance?", "doc": 4},

    # Document 5 – Practical deployment
    {"q": "What challenges arise when deploying trading models in real markets?", "doc": 5},
    {"q": "How do transaction costs impact trading performance?", "doc": 5},

    # Document 10 – Intel 10-K
    {"q": "What was Intel's revenue and profit in the latest 10-K?", "doc": 10},
    {"q": "What are the key risks Intel identifies in its 10-K filing?", "doc": 10},
    {"q": "What business segments contribute most to Intel’s revenue?", "doc": 10},
    {"q": "How does Intel describe competitive pressures in its 10-K?", "doc": 10},
]

# ──────────────────────────────────────────────────────────────────────────────
# 8. RUN ALL THREE EXPERIMENTS
# ──────────────────────────────────────────────────────────────────────────────
print("\n" + "═"*80)
print("STARTING FULL CHUNKING COMPARISON EXPERIMENT")
print("═"*80)

results_recursive = evaluate_strategy("Recursive Chunking", recursive_chunking, test_questions)
results_semantic   = evaluate_strategy("Semantic Chunking (LLM)", semantic_chunking, test_questions)
results_sentence   = evaluate_strategy("Sentence-Window Chunking", sentence_window_chunking, test_questions)

# ──────────────────────────────────────────────────────────────────────────────
# 9. SAVE RESULTS
# ──────────────────────────────────────────────────────────────────────────────
all_results = {
    'recursive': results_recursive,
    'semantic': results_semantic,
    'sentence_window': results_sentence
}

with open('chunking_results.json', 'w', encoding='utf-8') as f:
    json.dump(all_results, f, indent=2, ensure_ascii=False)

print("\n" + "═"*80)
print("EXPERIMENT COMPLETE!")
print("Detailed results saved → chunking_results.json")
print("═"*80)

# ──────────────────────────────────────────────────────────────────────────────
# 10. MANUAL EVALUATION GUIDELINES (unchanged)
# ──────────────────────────────────────────────────────────────────────────────
print("\n" + "═"*80)
print("MANUAL EVALUATION INSTRUCTIONS")
print("═"*80)
print("""
For each of the 20 questions, rate the answers from each strategy:

RETRIEVAL ACCURACY (0–1 scale):
  • 0   = No relevant information
  • 0.5 = Partial / tangential information
  • 1   = Directly relevant information

GENERATION QUALITY (1–5 scale):
  • 1 = Incorrect, incoherent, nonsensical
  • 2 = Partially correct, missing key info
  • 3 = Correct but lacks detail/clarity
  • 4 = Correct, clear, reasonably complete
  • 5 = Excellent – accurate, comprehensive, well-structured

Recommended spreadsheet columns:
Question | Recursive_Retrieval | Recursive_Quality | Semantic_Retrieval | Semantic_Quality | Sentence_Retrieval | Sentence_Quality

→ Calculate average scores per strategy at the bottom
""")